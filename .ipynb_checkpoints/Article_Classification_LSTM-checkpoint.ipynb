{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM - Article Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from time import time\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import log_loss\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26227, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_headline</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>type</th>\n",
       "      <th>valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslims BUSTED They Stole Millions In Govt Ben...</td>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>muslims bust steal millions in govt benefit</td>\n",
       "      <td>print should pay all the back all the money pl...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Re Why Did Attorney General Loretta Lynch Plea...</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>re why do attorney general loretta lynch plead...</td>\n",
       "      <td>why do attorney general loretta lynch plead th...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING Weiner Cooperating With FBI On Hillar...</td>\n",
       "      <td>Red State Fox News Sunday reported this mornin...</td>\n",
       "      <td>break weiner cooperate with fbi on hillary ema...</td>\n",
       "      <td>red state fox news sunday report this morning ...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
       "      <td>email kayla mueller be a prisoner and torture ...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FANTASTIC! TRUMPS 7 POINT PLAN To Reform Healt...</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>fantastic trump 7 point plan to reform healthc...</td>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Muslims BUSTED They Stole Millions In Govt Ben...   \n",
       "1  Re Why Did Attorney General Loretta Lynch Plea...   \n",
       "2  BREAKING Weiner Cooperating With FBI On Hillar...   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
       "4  FANTASTIC! TRUMPS 7 POINT PLAN To Reform Healt...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Print They should pay all the back all the mon...   \n",
       "1  Why Did Attorney General Loretta Lynch Plead T...   \n",
       "2  Red State Fox News Sunday reported this mornin...   \n",
       "3  Email Kayla Mueller was a prisoner and torture...   \n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...   \n",
       "\n",
       "                                  tokenized_headline  \\\n",
       "0        muslims bust steal millions in govt benefit   \n",
       "1  re why do attorney general loretta lynch plead...   \n",
       "2  break weiner cooperate with fbi on hillary ema...   \n",
       "3  pin drop speech by father of daughter kidnappe...   \n",
       "4  fantastic trump 7 point plan to reform healthc...   \n",
       "\n",
       "                                   tokenized_content  type  valid_score  \n",
       "0  print should pay all the back all the money pl...  bias            0  \n",
       "1  why do attorney general loretta lynch plead th...  bias            0  \n",
       "2  red state fox news sunday report this morning ...  bias            0  \n",
       "3  email kayla mueller be a prisoner and torture ...  bias            0  \n",
       "4  email healthcare reform to make america great ...  bias            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/briankalinowski/Desktop/Data/news_content_lemma.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_headline</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>type</th>\n",
       "      <th>valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslims BUSTED They Stole Millions In Govt Ben...</td>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>muslims bust steal millions in govt benefit</td>\n",
       "      <td>print should pay all the back all the money pl...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Re Why Did Attorney General Loretta Lynch Plea...</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>re why do attorney general loretta lynch plead...</td>\n",
       "      <td>why do attorney general loretta lynch plead th...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING Weiner Cooperating With FBI On Hillar...</td>\n",
       "      <td>Red State Fox News Sunday reported this mornin...</td>\n",
       "      <td>break weiner cooperate with fbi on hillary ema...</td>\n",
       "      <td>red state fox news sunday report this morning ...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
       "      <td>email kayla mueller be a prisoner and torture ...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FANTASTIC! TRUMPS 7 POINT PLAN To Reform Healt...</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>fantastic trump 7 point plan to reform healthc...</td>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Muslims BUSTED They Stole Millions In Govt Ben...   \n",
       "1  Re Why Did Attorney General Loretta Lynch Plea...   \n",
       "2  BREAKING Weiner Cooperating With FBI On Hillar...   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
       "4  FANTASTIC! TRUMPS 7 POINT PLAN To Reform Healt...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Print They should pay all the back all the mon...   \n",
       "1  Why Did Attorney General Loretta Lynch Plead T...   \n",
       "2  Red State Fox News Sunday reported this mornin...   \n",
       "3  Email Kayla Mueller was a prisoner and torture...   \n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...   \n",
       "\n",
       "                                  tokenized_headline  \\\n",
       "0        muslims bust steal millions in govt benefit   \n",
       "1  re why do attorney general loretta lynch plead...   \n",
       "2  break weiner cooperate with fbi on hillary ema...   \n",
       "3  pin drop speech by father of daughter kidnappe...   \n",
       "4  fantastic trump 7 point plan to reform healthc...   \n",
       "\n",
       "                                   tokenized_content  type  valid_score  \n",
       "0  print should pay all the back all the money pl...  bias            0  \n",
       "1  why do attorney general loretta lynch plead th...  bias            0  \n",
       "2  red state fox news sunday report this morning ...  bias            0  \n",
       "3  email kayla mueller be a prisoner and torture ...  bias            0  \n",
       "4  email healthcare reform to make america great ...  bias            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'] = [str(art) for art in df.title]\n",
    "df['text'] = [str(art) for art in df.text]\n",
    "df['tokenized_headline'] = [str(art) for art in df.tokenized_headline]\n",
    "df['tokenized_content'] = [str(art) for art in df.tokenized_content]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train / Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 600\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25978 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['title'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (26227, 600)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['title'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (26227, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['valid_score']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23604, 600) (23604, 2)\n",
      "(2623, 600) (2623, 2)\n"
     ]
    }
   ],
   "source": [
    "X_title_train, X_title_test, Y_title_train, Y_title_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_title_train.shape,Y_title_train.shape)\n",
    "print(X_title_test.shape,Y_title_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 600\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180034 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (26227, 600)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (26227, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['valid_score']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 600) (13113, 2)\n",
      "(13114, 600) (13114, 2)\n"
     ]
    }
   ],
   "source": [
    "X_text_train, X_text_test, Y_text_train, Y_text_test = train_test_split(X, Y, test_size = 0.50, random_state = 21)\n",
    "print(X_text_train.shape,Y_text_train.shape)\n",
    "print(X_text_test.shape,Y_text_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 600, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 600, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,042,370\n",
      "Trainable params: 5,042,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23604 samples, validate on 2623 samples\n",
      "Epoch 1/10\n",
      "23604/23604 [==============================] - 241s 10ms/sample - loss: 0.5180 - accuracy: 0.7250 - val_loss: 0.4161 - val_accuracy: 0.7964\n",
      "Epoch 2/10\n",
      "23604/23604 [==============================] - 238s 10ms/sample - loss: 0.3162 - accuracy: 0.8629 - val_loss: 0.4221 - val_accuracy: 0.8090\n",
      "Epoch 3/10\n",
      "23604/23604 [==============================] - 237s 10ms/sample - loss: 0.1989 - accuracy: 0.9233 - val_loss: 0.4860 - val_accuracy: 0.7918\n",
      "Epoch 4/10\n",
      "23604/23604 [==============================] - 237s 10ms/sample - loss: 0.1264 - accuracy: 0.9522 - val_loss: 0.6236 - val_accuracy: 0.7888\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_title_train, Y_title_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_title_test, Y_title_test),\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_title_pred = model.predict(X_title_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13113 samples, validate on 13114 samples\n",
      "WARNING:tensorflow:From /Users/anaconda3/envs/FakeNewsChallenge/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "13113/13113 [==============================] - 180s 14ms/sample - loss: 0.4937 - acc: 0.7563 - val_loss: 0.3951 - val_acc: 0.8198\n",
      "Epoch 2/10\n",
      "13113/13113 [==============================] - 177s 13ms/sample - loss: 0.2228 - acc: 0.9133 - val_loss: 0.2064 - val_acc: 0.9189\n",
      "Epoch 3/10\n",
      "13113/13113 [==============================] - 181s 14ms/sample - loss: 0.1318 - acc: 0.9552 - val_loss: 0.2100 - val_acc: 0.9234\n",
      "Epoch 4/10\n",
      "13113/13113 [==============================] - 183s 14ms/sample - loss: 0.1025 - acc: 0.9653 - val_loss: 0.2411 - val_acc: 0.9163\n",
      "Epoch 5/10\n",
      "13113/13113 [==============================] - 191s 15ms/sample - loss: 0.0555 - acc: 0.9831 - val_loss: 0.2537 - val_acc: 0.9181\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_text_train, Y_text_train, \n",
    "                    epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_text_test, Y_text_test),\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_text_pred = model.predict(X_text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Score Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_abs(row):\n",
    "    return abs((row.REAL - row.FAKE))\n",
    "\n",
    "def fake_weighted(row):\n",
    "    return row.FAKE / (row.REAL + row.FAKE)\n",
    "\n",
    "def real_weighted(row):\n",
    "    return row.REAL / (row.REAL + row.FAKE)\n",
    "\n",
    "def assign_valid_class(row):\n",
    "    # sum of the REAL and Fake scores (they are not probabilities)\n",
    "    score_sum = (row.REAL + row.FAKE)\n",
    "\n",
    "    # divide each score by their sum for weighted probabilities\n",
    "    weighted_real = row.REAL / score_sum\n",
    "    weighted_fake = row.FAKE / score_sum\n",
    "\n",
    "    if (weighted_real > weighted_fake) and (row.REAL >= 0.5) and (row.FAKE < 0.5):\n",
    "        valid_class = 1\n",
    "    elif (weighted_real < weighted_fake) and (row.FAKE >= 0.5) and (row.REAL < 0.5):\n",
    "        valid_class = 0\n",
    "    else:\n",
    "        # just default to the raw scores\n",
    "        if row.REAL > row.FAKE:\n",
    "            valid_class = 1\n",
    "        else:\n",
    "            valid_class = 0\n",
    "    return valid_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_score</th>\n",
       "      <th>REAL</th>\n",
       "      <th>FAKE</th>\n",
       "      <th>real_weighted_score</th>\n",
       "      <th>fake_weighted_score</th>\n",
       "      <th>score_abs</th>\n",
       "      <th>valid_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.485007</td>\n",
       "      <td>0.514993</td>\n",
       "      <td>0.485007</td>\n",
       "      <td>0.514993</td>\n",
       "      <td>0.029986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>0.983683</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>0.983683</td>\n",
       "      <td>0.967365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692342</td>\n",
       "      <td>0.307658</td>\n",
       "      <td>0.692342</td>\n",
       "      <td>0.307658</td>\n",
       "      <td>0.384684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.993795</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.993795</td>\n",
       "      <td>0.987590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980387</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.980387</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.960775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2619</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>0.984699</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>0.984699</td>\n",
       "      <td>0.969399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438745</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.438745</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.122511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2622</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095897</td>\n",
       "      <td>0.904103</td>\n",
       "      <td>0.095897</td>\n",
       "      <td>0.904103</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2623 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      valid_score      REAL      FAKE  real_weighted_score  \\\n",
       "0               1  0.485007  0.514993             0.485007   \n",
       "1               0  0.016317  0.983683             0.016317   \n",
       "2               1  0.692342  0.307658             0.692342   \n",
       "3               1  0.006205  0.993795             0.006205   \n",
       "4               1  0.980387  0.019613             0.980387   \n",
       "...           ...       ...       ...                  ...   \n",
       "2618            1  0.999973  0.000027             0.999973   \n",
       "2619            1  0.999781  0.000219             0.999781   \n",
       "2620            1  0.015301  0.984699             0.015301   \n",
       "2621            0  0.438745  0.561255             0.438745   \n",
       "2622            0  0.095897  0.904103             0.095897   \n",
       "\n",
       "      fake_weighted_score  score_abs  valid_prediction  \n",
       "0                0.514993   0.029986                 0  \n",
       "1                0.983683   0.967365                 0  \n",
       "2                0.307658   0.384684                 1  \n",
       "3                0.993795   0.987590                 0  \n",
       "4                0.019613   0.960775                 1  \n",
       "...                   ...        ...               ...  \n",
       "2618             0.000027   0.999946                 1  \n",
       "2619             0.000219   0.999562                 1  \n",
       "2620             0.984699   0.969399                 0  \n",
       "2621             0.561255   0.122511                 0  \n",
       "2622             0.904103   0.808205                 0  \n",
       "\n",
       "[2623 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_title_df = pd.DataFrame() #creates a new dataframe that's empty\n",
    "lstm_title_df['valid_score'] = np.argmax(Y_title_test, axis=1)\n",
    "lstm_title_df['REAL'] = Y_title_pred[:,1]\n",
    "lstm_title_df['FAKE'] = Y_title_pred[:,0]\n",
    "\n",
    "lstm_title_df['real_weighted_score'] = lstm_title_df.apply(real_weighted, axis=1)\n",
    "lstm_title_df['fake_weighted_score'] = lstm_title_df.apply(fake_weighted, axis=1)\n",
    "lstm_title_df['score_abs'] = lstm_title_df.apply(scores_abs, axis=1)\n",
    "lstm_title_df['valid_prediction'] = lstm_title_df.apply(assign_valid_class, axis=1)\n",
    "\n",
    "lstm_title_df.to_csv(path_or_buf=\"lstm_title_df.csv\", header=True, index=None)\n",
    "\n",
    "lstm_title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_score</th>\n",
       "      <th>REAL</th>\n",
       "      <th>FAKE</th>\n",
       "      <th>real_weighted_score</th>\n",
       "      <th>fake_weighted_score</th>\n",
       "      <th>score_abs</th>\n",
       "      <th>valid_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017029</td>\n",
       "      <td>0.982971</td>\n",
       "      <td>0.017029</td>\n",
       "      <td>0.982971</td>\n",
       "      <td>0.965942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.975015</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.975015</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.950030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.946720</td>\n",
       "      <td>0.053280</td>\n",
       "      <td>0.946720</td>\n",
       "      <td>0.053280</td>\n",
       "      <td>0.893440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996636</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.996636</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.993272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valid_score      REAL      FAKE  real_weighted_score  fake_weighted_score  \\\n",
       "0            0  0.017029  0.982971             0.017029             0.982971   \n",
       "1            1  0.975015  0.024985             0.975015             0.024985   \n",
       "2            1  0.946720  0.053280             0.946720             0.053280   \n",
       "3            0  0.000204  0.999796             0.000204             0.999796   \n",
       "4            1  0.996636  0.003364             0.996636             0.003364   \n",
       "\n",
       "   score_abs  valid_prediction  \n",
       "0   0.965942                 0  \n",
       "1   0.950030                 1  \n",
       "2   0.893440                 1  \n",
       "3   0.999591                 0  \n",
       "4   0.993272                 1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_text_df = pd.DataFrame() #creates a new dataframe that's empty\n",
    "lstm_text_df['valid_score'] = np.argmax(Y_text_test, axis=1)\n",
    "lstm_text_df['REAL'] = Y_text_pred[:,1]\n",
    "lstm_text_df['FAKE'] = Y_text_pred[:,0]\n",
    "\n",
    "lstm_text_df['real_weighted_score'] = lstm_text_df.apply(real_weighted, axis=1)\n",
    "lstm_text_df['fake_weighted_score'] = lstm_text_df.apply(fake_weighted, axis=1)\n",
    "lstm_text_df['score_abs'] = lstm_text_df.apply(scores_abs, axis=1)\n",
    "lstm_text_df['valid_prediction'] = lstm_text_df.apply(assign_valid_class, axis=1)\n",
    "\n",
    "lstm_text_df.to_csv(path_or_buf=\"/Users/briankalinowski/Desktop/Data/lstm_text_large_df.csv\", header=True, index=None)\n",
    "lstm_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
